import os
import warnings
# Note: google.generativeai is deprecated but still works
with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=FutureWarning)
    import google.generativeai as genai
from typing import Optional, List, Dict
import base64
import io
from PIL import Image

class GeminiClient:
    def __init__(self, api_key: Optional[str] = None):
        """
        Initialize Gemini API client with automatic model discovery.
        """
        self.api_key = api_key or os.getenv("GOOGLE_API_KEY")
        if not self.api_key:
            raise ValueError("Google API key not found. Please set GOOGLE_API_KEY in environment variables.")
        
        genai.configure(api_key=self.api_key)
        
        # Try models in order - gemini-pro is most reliable
        models_to_try = [
            'gemini-pro',           # Most stable and widely available
            'models/gemini-pro',    # With prefix
            'gemini-1.5-pro',       # Newer version
            'gemini-1.5-flash',    # Faster version
        ]
        
        model_initialized = False
        working_model = None
        
        print("üîç Initializing Gemini model...")
        
        for model_name in models_to_try:
            try:
                print(f"  Trying: {model_name}...")
                test_model = genai.GenerativeModel(model_name)
                # Quick test
                test_response = test_model.generate_content("hi")
                if test_response:
                    self.model = test_model
                    self.vision_model = genai.GenerativeModel(model_name)
                    working_model = model_name
                    print(f"‚úÖ Successfully initialized: {model_name}")
                    model_initialized = True
                    break
            except Exception as e:
                error_msg = str(e)
                if "404" in error_msg or "not found" in error_msg.lower():
                    print(f"  ‚ùå {model_name} not available")
                else:
                    print(f"  ‚ö†Ô∏è {model_name} error: {str(e)[:80]}")
                continue
        
        if not model_initialized:
            # Last attempt: list all models and try first available
            try:
                print("\nüîç Listing all available models...")
                all_models = list(genai.list_models())
                for model in all_models[:10]:  # Check first 10
                    model_name = model.name.split('/')[-1] if '/' in model.name else model.name
                    if model_name in models_to_try:
                        continue  # Already tried
                    
                    try:
                        print(f"  Trying: {model_name}...")
                        test_model = genai.GenerativeModel(model_name)
                        test_response = test_model.generate_content("hi")
                        if test_response:
                            self.model = test_model
                            self.vision_model = genai.GenerativeModel(model_name)
                            working_model = model_name
                            print(f"‚úÖ Successfully initialized: {model_name}")
                            model_initialized = True
                            break
                    except:
                        continue
            except Exception as e:
                print(f"‚ö†Ô∏è Could not list models: {e}")
        
        if not model_initialized:
            error_msg = """
‚ùå CRITICAL: Could not initialize any Gemini model!

Possible solutions:
1. Check your API key in backend/.env
2. Verify API is enabled in Google Cloud Console
3. Check API quota/limits
4. Run: python backend/test_models.py

Error details will be shown above.
"""
            print(error_msg)
            raise ValueError("Could not initialize Gemini model")
        
        print(f"üéØ Using model: {working_model}\n")

    def generate_text_response(
        self, 
        user_message: str, 
        conversation_history: Optional[List[Dict]] = None,
        language: str = "fr"
    ) -> str:
        """Generate a text response using Gemini API."""
        try:
            system_prompts = {
                "fr": """Tu es un assistant IA intelligent et tr√®s utile. Tu dois:
- R√©pondre √† TOUTES les questions de mani√®re directe et pr√©cise
- Comprendre le contexte et donner des r√©ponses compl√®tes
- Si tu ne connais pas quelque chose, dis-le honn√™tement
- Sois naturel, amical et professionnel
- R√©ponds toujours en fran√ßais""",
                "en": """You are an intelligent and very helpful AI assistant. You must:
- Answer ALL questions directly and accurately
- Understand context and provide complete answers
- If you don't know something, say so honestly
- Be natural, friendly, and professional
- Always respond in English""",
                "ar": """ÿ£ŸÜÿ™ ŸÖÿ≥ÿßÿπÿØ ÿ∞ŸÉŸä ŸàŸÖŸÅŸäÿØ ÿ¨ÿØŸãÿß. Ÿäÿ¨ÿ® ÿπŸÑŸäŸÉ:
- ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ© ÿπŸÑŸâ ÿ¨ŸÖŸäÿπ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿ®ÿ¥ŸÉŸÑ ŸÖÿ®ÿßÿ¥ÿ± ŸàÿØŸÇŸäŸÇ
- ŸÅŸáŸÖ ÿßŸÑÿ≥ŸäÿßŸÇ Ÿàÿ•ÿπÿ∑ÿßÿ° ÿ•ÿ¨ÿßÿ®ÿßÿ™ ŸÉÿßŸÖŸÑÿ©
- ÿ•ÿ∞ÿß ŸÉŸÜÿ™ ŸÑÿß ÿ™ÿπÿ±ŸÅ ÿ¥Ÿäÿ¶Ÿãÿßÿå ŸÇŸÑ ÿ∞ŸÑŸÉ ÿ®ÿµÿ±ÿßÿ≠ÿ©
- ŸÉŸÜ ÿ∑ÿ®ŸäÿπŸäŸãÿß ŸàŸàÿØŸàÿØŸãÿß ŸàŸÖŸáŸÜŸäŸãÿß
- ÿ£ÿ¨ÿ® ÿØÿßÿ¶ŸÖŸãÿß ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©"""
            }
            
            system_prompt = system_prompts.get(language, system_prompts["fr"])
            
            # Build conversation context
            conversation_context = ""
            if conversation_history:
                recent_history = conversation_history[-6:]
                for msg in recent_history:
                    role_label = {
                        "fr": {"user": "Utilisateur", "assistant": "Assistant"},
                        "en": {"user": "User", "assistant": "Assistant"},
                        "ar": {"user": "ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ", "assistant": "ÿßŸÑŸÖÿ≥ÿßÿπÿØ"}
                    }
                    role_name = role_label[language].get(msg.get("role", "user"), "User")
                    conversation_context += f"{role_name}: {msg.get('content', '')}\n"
            
            # Build prompt
            if conversation_context:
                if language == "ar":
                    prompt = f"{system_prompt}\n\nÿ™ÿßÿ±ŸäÿÆ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ©:\n{conversation_context}\nÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ: {user_message}\nÿßŸÑŸÖÿ≥ÿßÿπÿØ:"
                elif language == "fr":
                    prompt = f"{system_prompt}\n\nHistorique de la conversation:\n{conversation_context}\nUtilisateur: {user_message}\nAssistant:"
                else:
                    prompt = f"{system_prompt}\n\nConversation history:\n{conversation_context}\nUser: {user_message}\nAssistant:"
            else:
                if language == "ar":
                    prompt = f"{system_prompt}\n\nÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ: {user_message}\nÿßŸÑŸÖÿ≥ÿßÿπÿØ:"
                elif language == "fr":
                    prompt = f"{system_prompt}\n\nUtilisateur: {user_message}\nAssistant:"
                else:
                    prompt = f"{system_prompt}\n\nUser: {user_message}\nAssistant:"
            
            # Generate response
            response = self.model.generate_content(prompt)
            
            # Extract text from response
            if hasattr(response, 'text') and response.text:
                return response.text.strip()
            
            if hasattr(response, 'candidates') and len(response.candidates) > 0:
                candidate = response.candidates[0]
                if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                    if len(candidate.content.parts) > 0:
                        part = candidate.content.parts[0]
                        if hasattr(part, 'text') and part.text:
                            return part.text.strip()
            
            return str(response).strip()
            
        except Exception as e:
            error_msg = {
                "fr": f"D√©sol√©, une erreur s'est produite: {str(e)[:150]}",
                "en": f"Sorry, an error occurred: {str(e)[:150]}",
                "ar": f"ÿπÿ∞ÿ±Ÿãÿßÿå ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£: {str(e)[:150]}"
            }
            print(f"‚ùå Gemini API Error: {e}")
            return error_msg.get(language, error_msg["fr"])

    def generate_image_response(
        self,
        user_message: str,
        image_data: bytes,
        conversation_history: Optional[List[Dict]] = None,
        language: str = "fr"
    ) -> str:
        """Generate a response based on image and text using Gemini Vision API."""
        try:
            # Convert image bytes to PIL Image
            image = Image.open(io.BytesIO(image_data))
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # Build prompt
            if not user_message or not user_message.strip():
                prompts = {
                    "fr": "Analyse cette image en d√©tail et d√©cris tout ce que tu vois.",
                    "en": "Analyze this image in detail and describe everything you see.",
                    "ar": "ÿ≠ŸÑŸÑ Ÿáÿ∞Ÿá ÿßŸÑÿµŸàÿ±ÿ© ÿ®ÿßŸÑÿ™ŸÅÿµŸäŸÑ ŸàŸàÿµŸÅ ŸÉŸÑ ŸÖÿß ÿ™ÿ±ÿßŸá."
                }
            else:
                prompts = {
                    "fr": f"Analyse cette image et r√©ponds √† cette question en fran√ßais: {user_message}",
                    "en": f"Analyze this image and answer this question in English: {user_message}",
                    "ar": f"ÿ≠ŸÑŸÑ Ÿáÿ∞Ÿá ÿßŸÑÿµŸàÿ±ÿ© Ÿàÿ£ÿ¨ÿ® ÿπŸÑŸâ Ÿáÿ∞ÿß ÿßŸÑÿ≥ÿ§ÿßŸÑ ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ©: {user_message}"
                }
            
            prompt = prompts.get(language, prompts["fr"])
            
            # Generate response
            response = self.vision_model.generate_content([prompt, image])
            
            # Extract text
            if hasattr(response, 'text') and response.text:
                return response.text.strip()
            
            if hasattr(response, 'candidates') and len(response.candidates) > 0:
                candidate = response.candidates[0]
                if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                    if len(candidate.content.parts) > 0:
                        part = candidate.content.parts[0]
                        if hasattr(part, 'text') and part.text:
                            return part.text.strip()
            
            return str(response).strip()
            
        except Exception as e:
            error_msg = {
                "fr": f"Erreur lors de l'analyse de l'image: {str(e)[:150]}",
                "en": f"Error analyzing image: {str(e)[:150]}",
                "ar": f"ÿÆÿ∑ÿ£ ŸÅŸä ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ±ÿ©: {str(e)[:150]}"
            }
            print(f"‚ùå Vision API Error: {e}")
            return error_msg.get(language, error_msg["fr"])

# Global instance
gemini_client = None

def get_gemini_client() -> Optional[GeminiClient]:
    """Get or create Gemini client instance"""
    global gemini_client
    if gemini_client is None:
        try:
            gemini_client = GeminiClient()
        except Exception as e:
            print(f"‚ö†Ô∏è Warning: Could not initialize Gemini client: {e}")
            return None
    return gemini_client
